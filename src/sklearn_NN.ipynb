{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9049c9f-1af2-4a54-9c85-f7747ed76ec1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output before training: [1.0594495]\n",
      "Output after training:  [1.0594495]\n",
      "Loss before training:   0.001767\n",
      "Loss after training:    0.001767\n",
      "Weights from sklearn: [array([[0.06923925, 0.30305661],\n",
      "       [0.14540973, 0.06296867]]), array([[-0.10989762],\n",
      "       [ 0.63009203]])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:781: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Data\n",
    "X = np.array([[0.5, 0.2]])\n",
    "y = np.array([1])\n",
    "\n",
    "# Initialize model (SGD optimizer, logistic activation)\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(2,),\n",
    "                   activation='logistic',\n",
    "                   solver='sgd',\n",
    "                   learning_rate_init=0.1,\n",
    "                   max_iter=1,\n",
    "                   random_state=0)\n",
    "\n",
    "# --- Step 1: Fit once to trigger weight initialization ---\n",
    "mlp._fit(X, y, incremental=True)  # initialize weights only (internal scikit-learn trick)\n",
    "\n",
    "# Forward pass BEFORE training\n",
    "# The raw output layer before any optimization step\n",
    "y_pred_before = mlp._predict(X)   # private fast forward pass\n",
    "loss_before = mean_squared_error(y, y_pred_before) / 2\n",
    "\n",
    "# --- Step 2: Train the model for 1 iteration ---\n",
    "mlp.fit(X, y)\n",
    "\n",
    "# Forward pass AFTER training\n",
    "y_pred_after = mlp.predict(X)\n",
    "loss_after = mean_squared_error(y, y_pred_after) / 2\n",
    "\n",
    "# --- Step 3: Display results ---\n",
    "print(f\"Output before training: {y_pred_before}\")\n",
    "print(f\"Output after training:  {y_pred_after}\")\n",
    "print(f\"Loss before training:   {loss_before:.6f}\")\n",
    "print(f\"Loss after training:    {loss_after:.6f}\")\n",
    "print(\"Weights from sklearn:\", mlp.coefs_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd854d1b-6777-49b1-9e78-28aea3b7d187",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
